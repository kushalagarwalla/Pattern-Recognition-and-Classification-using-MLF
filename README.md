# A novel technique for fuzzy based pattern recognition and classification 
Anything which can be perceived physically or observed mathematically by applying a certain set of formulae is known as pattern. One uses pattern classification to find categorical labels for a set of observations. Pattern Classification Models are Artificial neural networks, Fuzzy Logic and Hybrid Model. Hybrid models are the models that combine fuzzy logic and artificial neural networks together. ‘Multi-Level Fuzzy Min-Max Neural Network’ is used for pattern classification in this repository. 
### Multi-Level Fuzzy Min-Max Neural Network
MLF uses basic concepts of the fuzzy min-max (FMM) method in a multi-level structure to classify patterns. This method uses separate classifiers with smaller hyperboxes in different levels to classify the samples that are located in overlapping regions. The final output of the network is formed by combining the outputs of these classifiers. MLF is capable of learning nonlinear boundaries with a single pass through the data. According to the obtained results, the MLF method, compared to the other FMM networks, has the highest performance and the lowest sensitivity to maximum size of the hyperbox parameter (θ), with a training accuracy of 100% in most cases.
#### Architecture
The proposed method uses a multi-level tree structure. Each node of this network is a separate classifier and has two major segments called hyperboxessegment (HBS) and overlap boxes segment (OLS). Both segments are created in the training phase. The OLS is iscreated at end of this phase when the HBS is completed. HBS contains hyperboxes, and OLS stores overlap boxes. Each of the boxes in OLS represents an overlapped region in the HBS.
An overlap box is an n-dimensional box like a hyperbox defined by a min point and a max point. Each overlap box represents the range of the corresponding overlapped region. And also, the box is related to a node in the next level of the network (child subnet) that is connected to the box with a trigger edge. Transaction function of node G determines output of the subnet (node) depending on o and c where o is output of OLS and c is output of HBS. Like the output of original FMM, o is a set of real numbers between 0 and 1 that specifies the membership of each class.
#### Training Phase
Structure of the network is formed in training phase, and the required subnets in different levels are created. Here, each node is trained separately by samples that belong to its region. Learning function of each node consists of two steps: 1) hyperbox development and 2) overlap handling. HBS and OLS are created in these steps, respectively. Additionally, in the overlap handling step, children nodes are created, and running their learning function causes them to form their structure.
* Hyper Box Development:
Hyperboxes of HBS are created and adjusted in this step. Like previous methods, when a training sample is presented, if the pattern is in an existing hyperbox with the same class, no adjustment of the min and max points of the hyperbox is necessary. Otherwise, a hyperbox is expanded. Finally, a hyperbox in HBS section is created if the existing hyperboxes of that class cannot be expanded further to accommodate the pattern.
* Overlap Handling:
This step of training phase that is executed after creation of HBS in the subnet handles overlaps created in HBS. In this step, all overlapped areas of HBS are identified and a new overlap box is created for each of them. Overlap box’s minpoint and maxpoint are set equal to minpoint and maxpoint of the overlapped region. Additionally, a subnet is created in the next level corresponding to each of these “overlap boxes” (child node). The subnet structure is quite similar to its parent and is trained by samples that belong to this overlapped area. This operation is performed recursively and causes the recall of the training function of other nodes in depth-first order. In other words, only the training function of the root subnet is recalled to create and train all subnets. 
Note that all hyperboxes of each child subnet are created in the overlapped areas of its parent. So in most cases, the child’s hyperboxes will be smaller than the parent’s hyperboxes, and hence the child has more accuracy than its parent.
#### Classifying Phase
The output in proposed method may be computed in nodes which are not leaves. In other words, the best subnet is selected depending on its domain and position of the test sample, and the output of the subnet will be used as the output of the network. In this process, the outputs of all subnets are computed. Outputs of HBS and OLS must be computed first. HBS is similar to the original FMM and returns a membership value for each class. Finally, the class with the largest amount of gs among all these outputs is returned as the output of the network.
